{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e43ff5",
   "metadata": {},
   "source": [
    "This notebook builds on EDA done here: https://github.com/fractaldatalearning/Capstone2/blob/main/notebooks/eda3_1user_modeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb561914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "from library.sb_utils import save_file\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c648bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33819106 entries, 0 to 33819105\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   order_id                int64  \n",
      " 1   user_id                 int64  \n",
      " 2   order_by_user_sequence  int64  \n",
      " 3   order_dow               int64  \n",
      " 4   order_hour_of_day       int64  \n",
      " 5   days_since_prior_order  float64\n",
      " 6   add_to_cart_sequence    int64  \n",
      " 7   reordered               int64  \n",
      " 8   product_name            object \n",
      " 9   aisle_name              object \n",
      " 10  dept_name               object \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "# import the original full df, drop  useless/redundant columns\n",
    "df = pd.read_csv('../data/processed/full_data_cleaned.csv')\n",
    "df = df.drop(columns = ['product_id', 'aisle_id', 'department_id', 'eval_set'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040f6aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7': 'beverages',\n",
       " '16': 'dairy eggs',\n",
       " '19': 'snacks',\n",
       " '17': 'household',\n",
       " '4': 'produce',\n",
       " '14': 'breakfast',\n",
       " '13': 'pantry',\n",
       " '20': 'deli',\n",
       " '1': 'frozen',\n",
       " '11': 'personal care',\n",
       " '12': 'meat seafood',\n",
       " '6': 'international',\n",
       " '3': 'bakery',\n",
       " '15': 'canned goods',\n",
       " '9': 'dry goods pasta',\n",
       " '5': 'alcohol',\n",
       " '8': 'pets',\n",
       " '18': 'babies',\n",
       " '2': 'other',\n",
       " '21': 'missing',\n",
       " '10': 'bulk'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dictionaries connecting product-aisle-dept\n",
    "\n",
    "with open('../data/processed/dicts/aisle_dept_dict.txt', \n",
    "          'r') as ad_file:\n",
    "     ad_dict = json.load(ad_file)\n",
    "\n",
    "with open('../data/processed/dicts/prod_aisle_dict.txt', \n",
    "          'r') as pa_file:\n",
    "     pa_dict = json.load(pa_file)\n",
    "        \n",
    "with open('../data/processed/dicts/dept_id_name_dict.txt', \n",
    "          'r') as dd_file:\n",
    "     dd_dict = json.load(dd_file)\n",
    "        \n",
    "with open('../data/processed/dicts/aisle_id_name_dict.txt', \n",
    "          'r') as aa_file:\n",
    "     aa_dict = json.load(aa_file)\n",
    "        \n",
    "with open('../data/processed/dicts/prod_id_name_dict.txt', \n",
    "          'r') as pp_file:\n",
    "     pp_dict = json.load(pp_file)\n",
    "        \n",
    "dd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7314d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 'beverages',\n",
       " 16: 'dairy eggs',\n",
       " 19: 'snacks',\n",
       " 17: 'household',\n",
       " 4: 'produce',\n",
       " 14: 'breakfast',\n",
       " 13: 'pantry',\n",
       " 20: 'deli',\n",
       " 1: 'frozen',\n",
       " 11: 'personal care',\n",
       " 12: 'meat seafood',\n",
       " 6: 'international',\n",
       " 3: 'bakery',\n",
       " 15: 'canned goods',\n",
       " 9: 'dry goods pasta',\n",
       " 5: 'alcohol',\n",
       " 8: 'pets',\n",
       " 18: 'babies',\n",
       " 2: 'other',\n",
       " 21: 'missing',\n",
       " 10: 'bulk'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix dictionary to make the keys int rather than str\n",
    "\n",
    "pp_dict = {int(k):v for k,v in pp_dict.items()}\n",
    "aa_dict = {int(k):v for k,v in aa_dict.items()}\n",
    "dd_dict = {int(k):v for k,v in dd_dict.items()}\n",
    "pa_dict = {int(k):v for k,v in pa_dict.items()}\n",
    "ad_dict = {int(k):v for k,v in ad_dict.items()}\n",
    "\n",
    "dd_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e9674",
   "metadata": {},
   "source": [
    "Decide what chunk of data to work with for the remainder of the project. Randomly choose users of some quantity to leave me with a df sized to function with the computer. Don't start out separating it into train/test split. My intuition is that cross-row calculations don't count as leakage and negatively impact modeling if I'm adding data that has to do with past orders. If this logic turns out to be inappropriate, I can just come back and split the set into separate users (or into certain orders per user) and re-run any subsequent code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785d0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total users are there?\n",
    "len(df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ee7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 351399 entries, 52947 to 33799613\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   order_id                351399 non-null  int64  \n",
      " 1   user_id                 351399 non-null  int64  \n",
      " 2   order_by_user_sequence  351399 non-null  int64  \n",
      " 3   order_dow               351399 non-null  int64  \n",
      " 4   order_hour_of_day       351399 non-null  int64  \n",
      " 5   days_since_prior_order  330558 non-null  float64\n",
      " 6   add_to_cart_sequence    351399 non-null  int64  \n",
      " 7   reordered               351399 non-null  int64  \n",
      " 8   product_name            351399 non-null  object \n",
      " 9   aisle_name              351399 non-null  object \n",
      " 10  dept_name               351399 non-null  object \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 32.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1% (appx. 2k) users seems like a reasonable place to start. Just see what happens after I add rows. \n",
    "# Randomly select 1% of users.\n",
    "users = random.sample(list(set(df['user_id'].unique())), 2062)\n",
    "df = df.loc[df['user_id'].isin(users), :]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb22a67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8111b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xz/sq63wkqx22q0t_hr7_1jfrhr0000gn/T/ipykernel_36339/981715766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Before adding rows, I'll need a dictionary of details to include in each new row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m order_deets = df.groupby('user_id')[['order_by_user_sequence','order_id', 'order_by_user_sequence',\n\u001b[0m\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m'order_dow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'order_hour_of_day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     'aisle_name', 'dept_name']].apply(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \"\"\"\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_indexed_same\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xz/sq63wkqx22q0t_hr7_1jfrhr0000gn/T/ipykernel_36339/981715766.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m'order_dow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'order_hour_of_day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'days_since_prior_order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     'aisle_name', 'dept_name']].apply(\n\u001b[0;32m----> 6\u001b[0;31m     lambda x: x.set_index('order_by_user_sequence').to_dict(orient='index')).to_dict()\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0morders_deets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5556\u001b[0m                 )\n\u001b[1;32m   5557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5558\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index_from_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index_from_sequences\u001b[0;34m(sequences, names)\u001b[0m\n\u001b[1;32m   6997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6998\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6999\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7000\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7001\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_to_subclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0mdisallow_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_ensure_array\u001b[0;34m(cls, data, dtype, copy)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;31m# GH#13601, GH#20285, GH#27125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Before adding rows, I'll need a dictionary of details to include in each new row.\n",
    "\n",
    "df.groupby('user_id', 'order_by_user_sequence')[[order_id, user_id, order_by_user_sequence, order_dow]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f97b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rows so that every order contains ever product ever ordered, with new rows as non-orders.\n",
    "# In the processing of editing this to make it work for df here with more users.\n",
    "for user in users:\n",
    "    # Make sure to only work with one user's orders at a time.\n",
    "    rows_to_work_with = df[df['user_id']==user]\n",
    "    for n in range(2,100):\n",
    "        # Get items from order n not reordered in order n+1\n",
    "        order_n = rows_to_work_with[rows_to_work_with['order_by_user_sequence']==n]['product_id'].unique().tolist()\n",
    "        order_n1 = rows_to_work_with[rows_to_work_with['order_by_user_sequence']==(n+1)]['product_id'].unique().tolist()\n",
    "        only_n = [x for x in order_n if x not in order_n1]\n",
    "        # Get n1 deets from the big deets dict\n",
    "        order_n1_deets = orders_deets.get(n+1)\n",
    "        # Add to n1 deets dict with product ids from order_n\n",
    "        order_n1_deets.update({'product_id': only_n})\n",
    "        # Turn dict into df of new rows\n",
    "        order_n1_new_rows = pd.DataFrame.from_dict(order_n1_deets)\n",
    "        # Add new rows to df\n",
    "        df = pd.concat([df, order_n1_new_rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa616de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reorders_so_far column.\n",
    "# Code I used with the practice user:\n",
    "\n",
    "previous_round_items = set(df[df['reorders_so_far']==3][\n",
    "    'product_name'])\n",
    "\n",
    "grouped_by_product = df[df['reorders_so_far']==3].groupby(\n",
    "    'product_name')['order_by_user_sequence']\n",
    "df['keep'] = df.assign(min=grouped_by_product.transform(min))['min']\n",
    "\n",
    "for n in range (4,47):\n",
    "    for order in range(7,101):\n",
    "        items_this_order = set(products_reordered_each_order[order])\n",
    "        reordered_this_iteration = set(\n",
    "            previous_round_items.intersection(items_this_order))\n",
    "        rows_to_change = df.loc[(df.loc[\n",
    "        :,'order_by_user_sequence']==order) & (df.loc[\n",
    "        :, 'reorders_so_far']==n-1) & (df['order_by_user_sequence']!=\n",
    "        df['keep']) & (df.loc[:,'product_name'].isin(\n",
    "        reordered_this_iteration))]\n",
    "        df.loc[rows_to_change.index, 'reorders_so_far'] = n\n",
    "    previous_round_items = set(df[df['reorders_so_far']==n][\n",
    "        'product_name'])\n",
    "    grouped_by_product = df[df['reorders_so_far']==n].groupby(\n",
    "        'product_name')['order_by_user_sequence']\n",
    "    df['keep'] = df.assign(min=grouped_by_product.transform(min))[\n",
    "        'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93604048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create past_orders column & delete reorders_so_far\n",
    "# Code I used to create past_orders with one user:\n",
    "\n",
    "items_already_ordered_ntimes = set(df[df['past_orders']==2][\n",
    "    'product_name'])\n",
    "when_items_first_ordered = list(df.groupby('product_name')[\n",
    "    'order_by_user_sequence'].idxmin())\n",
    "\n",
    "for n in range(2,47): \n",
    "    rows_npast = df[df['product_name'].isin(\n",
    "    items_already_ordered_ntimes)]\n",
    "    rows_npast = rows_npast[rows_npast['past_orders']==0]\n",
    "    rows_npast = rows_npast.drop(when_items_first_ordered, axis=0, \n",
    "                             errors='ignore')\n",
    "    when_reordered_ntimes = df[df['reorders_so_far']==n].set_index(\n",
    "    'product_name').to_dict()['order_by_user_sequence']\n",
    "    for prod, order in when_reordered_ntimes.items():\n",
    "        ind_to_delete = rows_npast[(rows_npast['product_name']==prod) &\n",
    "                                   (rows_npast[\n",
    "                                       'order_by_user_sequence']\n",
    "                                    >order)].index\n",
    "        rows_npast = rows_npast.drop(ind_to_delete)\n",
    "    df.loc[np.array(rows_npast.index),'past_orders'] = n\n",
    "    items_already_ordered_ntimes = set(df[df['past_orders']==n][\n",
    "        'product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f40df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer columns for product keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05973d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change format of dow, hour columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save work done so far as new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce594aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to new notebook for encoding & standardizing remaining features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
