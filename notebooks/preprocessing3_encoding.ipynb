{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81427551",
   "metadata": {},
   "source": [
    "This is the final preprocessing notebook before modeling. Here, I'll try out models' performances given various variable encoding strategies. I might want to balance the data in addition to focusing on F1, kappa and ROC curves as metrics, to see if that would actually improve model performance. I might also need to explore the possibility of feature reduction; I created multiple features in the previous notebook but am not yet sure if they'll be valuable in making predictions. I can begin to explore various models in the process of all this. \n",
    "\n",
    "Notebook on which this one builds: https://github.com/fractaldatalearning/Capstone2/blob/main/notebooks/preprocessing2_feature_engineering.ipynb\n",
    "\n",
    "One thing to look out for in this notebook: If I'm modeling and the computer is doing fine processing the dataset at this size, I could go back to the notebook for preprocessing1, add more rows to further increments of the full original dataset, concatenate them, re-run all the feature engineering steps with the larger dataset, and come back here to try out modeling with more rows (from twice as many, perhaps up to 10 times as many). I could also try a Naive Bayes classifier, which can be used when not all training data fits in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ff6ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from library.sb_utils import save_file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = './alert.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd07efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 218232 entries, 0 to 218231\n",
      "Data columns (total 27 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   order_id                 218232 non-null  int64  \n",
      " 1   user_id                  218232 non-null  int64  \n",
      " 2   order_by_user_sequence   218232 non-null  int64  \n",
      " 3   days_since_prior_order   218232 non-null  float64\n",
      " 4   add_to_cart_sequence     218232 non-null  int64  \n",
      " 5   reordered                218232 non-null  int64  \n",
      " 6   product_name             218232 non-null  object \n",
      " 7   aisle_name               218232 non-null  object \n",
      " 8   dept_name                218232 non-null  object \n",
      " 9   prior_purchases          218232 non-null  int64  \n",
      " 10  purchased_percent_prior  218232 non-null  float64\n",
      " 11  free                     218232 non-null  int64  \n",
      " 12  fresh                    218232 non-null  int64  \n",
      " 13  mix                      218232 non-null  int64  \n",
      " 14  natural                  218232 non-null  int64  \n",
      " 15  organic                  218232 non-null  int64  \n",
      " 16  original                 218232 non-null  int64  \n",
      " 17  sweet                    218232 non-null  int64  \n",
      " 18  white                    218232 non-null  int64  \n",
      " 19  whole                    218232 non-null  int64  \n",
      " 20  rice                     218232 non-null  int64  \n",
      " 21  fruit                    218232 non-null  int64  \n",
      " 22  gluten                   218232 non-null  int64  \n",
      " 23  dow_sin                  218232 non-null  float64\n",
      " 24  dow_cos                  218232 non-null  float64\n",
      " 25  hour_sin                 218232 non-null  float64\n",
      " 26  hour_cos                 218232 non-null  float64\n",
      "dtypes: float64(6), int64(18), object(3)\n",
      "memory usage: 45.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/features_engineered.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760818f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'order_by_user_sequence', 'days_since_prior_order',\n",
       "       'add_to_cart_sequence', 'reordered', 'product_name', 'aisle_name',\n",
       "       'dept_name', 'prior_purchases', 'purchased_percent_prior', 'free',\n",
       "       'fresh', 'mix', 'natural', 'organic', 'original', 'sweet', 'white',\n",
       "       'whole', 'rice', 'fruit', 'gluten', 'dow_sin', 'dow_cos', 'hour_sin',\n",
       "       'hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order_id is redundant as a combination of user and order_by_user_sequence. Delete it. \n",
    "df = df.drop(columns='order_id')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cb4bfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0973001209721764"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reordered'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f6f77",
   "metadata": {},
   "source": [
    "I can judge effect of my work by comparing model scores with scores of what would happen if I just guess that a random 10% of items get reordered (since 0.097 is the average of the whole 'reordered' column in this dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd992454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218232"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an array with 21823 1s randomly dispersed aming the rest 0s. Then use that fake array\n",
    "# as predictions to see what scores I'd get without using any of the work I've done/ will do. \n",
    "ones = [1] * 21823\n",
    "zeroes = [0] * 196409\n",
    "array = np.concatenate([ones, zeroes])\n",
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a0420e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3df325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(array)\n",
    "array[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c8231d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake conf matrix:  [[177291  19707]\n",
      " [ 19118   2116]]\n",
      "fake RF f1 score:  0.09828831548877069\n",
      "fake RF kappa score:  -0.0003803398371760025\n",
      "fake RF roc_auc score:  0.499807476856609\n"
     ]
    }
   ],
   "source": [
    "print('fake baseline conf matrix: ', metrics.confusion_matrix(y, array))\n",
    "print('fake baseline RF f1 score: ', metrics.f1_score(y, array))\n",
    "print('fake baseline RF kappa score: ', metrics.cohen_kappa_score(y, array))\n",
    "print('fake baseline RF roc_auc score: ', metrics.roc_auc_score(y, array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09f4a8",
   "metadata": {},
   "source": [
    "My understanding is that categorical features should be encoded prior to any standardization of ordinal features. Start here. \n",
    "\n",
    "I'd like to try multiple encoders for categorical data. A summary of my current knowledge of encoders that could make sense for this data:\n",
    "- One-Hot could work for the dept_name column because there are only 19 categories, much fewer than all the other categorical columns. It wouldn't work for any of the others. \n",
    "- Hashing works with high-cardinality variables but isn't reversible and can lead to some (usuall minimal, as far as I've read) info loss. It's not clear to me whether it involves any leakage across rows. \n",
    "- My understanding of binary encoding is that it's the best of both worlds from one-hot and hashing: fewer resultant categories than one-hot but interpretable and no info loss, unlike hashing. \n",
    "- My understanding is that Bayesian encoders generally cause contamination, so make sure to split into training and test sets prior to encoding. I read that LeaveOneOut is a Bayesian encoder that avoids leakage by not using the dependent variable.  I also read that it is especially good for classification tasks, so it's a good one to consider here.\n",
    "- I know very little about WeightofEvidence but it's another Bayesian encoders recommended by Springboard and I can try it out along with Target encoder (though I'd expect Target to over-fit compared with LeaveOneOut). \n",
    "\n",
    "I'd like any encoder(s) I use to be included in an eventual modeling pipeline, but first I want to explore and try them out individually to see better how they would each work with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by just predicting the reordered column. Perhaps try predicting the add_to_cart_sequence\n",
    "# column later. Create independent & dependent variables, encode independent categories. \n",
    "X = df.drop(columns=['reordered', 'add_to_cart_sequence'])\n",
    "y = df['reordered']\n",
    "\n",
    "categorical_columns = ['user_id', 'product_name', 'aisle_name', 'dept_name']\n",
    "ce_bin = ce.BinaryEncoder(cols=categorical_columns)\n",
    "Xbin = ce_bin.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d62d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id_0', 'user_id_1', 'user_id_2', 'user_id_3', 'user_id_4',\n",
       "       'user_id_5', 'user_id_6', 'user_id_7', 'order_by_user_sequence',\n",
       "       'days_since_prior_order', 'product_name_0', 'product_name_1',\n",
       "       'product_name_2', 'product_name_3', 'product_name_4', 'product_name_5',\n",
       "       'product_name_6', 'product_name_7', 'product_name_8', 'product_name_9',\n",
       "       'product_name_10', 'product_name_11', 'product_name_12', 'aisle_name_0',\n",
       "       'aisle_name_1', 'aisle_name_2', 'aisle_name_3', 'aisle_name_4',\n",
       "       'aisle_name_5', 'aisle_name_6', 'aisle_name_7', 'dept_name_0',\n",
       "       'dept_name_1', 'dept_name_2', 'dept_name_3', 'dept_name_4',\n",
       "       'prior_purchases', 'purchased_percent_prior', 'free', 'fresh', 'mix',\n",
       "       'natural', 'organic', 'original', 'sweet', 'white', 'whole', 'rice',\n",
       "       'fruit', 'gluten', 'dow_sin', 'dow_cos', 'hour_sin', 'hour_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xbin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc6bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary bagging conf matrix:  [[57890  1077]\n",
      " [ 5211  1292]]\n",
      "binary bagging f1 score:  0.2912533814247069\n",
      "binary bagging kappa score:  0.2515519082836193\n",
      "binary bagging roc_auc score:  0.5902065402234833\n"
     ]
    }
   ],
   "source": [
    "# Test out encoder performance in Bagging and RandomForest models. \n",
    "# These were overwhelmingly better than others when trying them out with a practice user.\n",
    "# First need to standardize. Don't bother yet with tuning model hyperparameters.\n",
    "\n",
    "Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(Xbin, y, test_size=0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xbin_train_scaled = scaler.fit_transform(Xbin_train)\n",
    "Xbin_test_scaled = scaler.transform(Xbin_test)\n",
    "\n",
    "bgg_clf = BaggingClassifier()\n",
    "bgg_clf = bgg_clf.fit(Xbin_train_scaled, ybin_train)\n",
    "ybin_pred = bgg_clf.predict(Xbin_test_scaled)\n",
    "print('binary bagging conf matrix: ', metrics.confusion_matrix(ybin_test, ybin_pred))\n",
    "print('binary bagging f1 score: ', metrics.f1_score(ybin_test, ybin_pred))\n",
    "print('binary bagging kappa score: ', metrics.cohen_kappa_score(ybin_test, ybin_pred))\n",
    "print('binary bagging roc_auc score: ', metrics.roc_auc_score(ybin_test, ybin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c266eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary RF conf matrix:  [[58252   715]\n",
      " [ 5149  1354]]\n",
      "binary RF f1 score:  0.3159122725151656\n",
      "binary RF kappa score:  0.2814589323552821\n",
      "binary RF roc_auc score:  0.5980430842814234\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = rf_clf.fit(Xbin_train_scaled, ybin_train)\n",
    "ybin_pred = rf_clf.predict(Xbin_test_scaled)\n",
    "print('binary RF conf matrix: ', metrics.confusion_matrix(ybin_test, ybin_pred))\n",
    "print('binary RF f1 score: ', metrics.f1_score(ybin_test, ybin_pred))\n",
    "print('binary RF kappa score: ', metrics.cohen_kappa_score(ybin_test, ybin_pred))\n",
    "print('binary RF roc_auc score: ', metrics.roc_auc_score(ybin_test, ybin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87138f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_by_user_sequence</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_name</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>prior_purchases</th>\n",
       "      <th>purchased_percent_prior</th>\n",
       "      <th>free</th>\n",
       "      <th>fresh</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>white</th>\n",
       "      <th>whole</th>\n",
       "      <th>rice</th>\n",
       "      <th>fruit</th>\n",
       "      <th>gluten</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207885</th>\n",
       "      <td>0.102878</td>\n",
       "      <td>32</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.251969</td>\n",
       "      <td>0.101280</td>\n",
       "      <td>0.138683</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>0.200077</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.126638</td>\n",
       "      <td>0.108402</td>\n",
       "      <td>0.124511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74749</th>\n",
       "      <td>0.133904</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.150568</td>\n",
       "      <td>0.138683</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52504</th>\n",
       "      <td>0.099180</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.019435</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167960</th>\n",
       "      <td>0.185663</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.138187</td>\n",
       "      <td>0.132272</td>\n",
       "      <td>3</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138319</th>\n",
       "      <td>0.067222</td>\n",
       "      <td>64</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074534</td>\n",
       "      <td>0.091347</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22463</th>\n",
       "      <td>0.128951</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.046358</td>\n",
       "      <td>0.088060</td>\n",
       "      <td>0.138683</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110838</th>\n",
       "      <td>0.147027</td>\n",
       "      <td>15</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.108402</td>\n",
       "      <td>0.124511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89280</th>\n",
       "      <td>0.134167</td>\n",
       "      <td>45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.097122</td>\n",
       "      <td>0.088838</td>\n",
       "      <td>11</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26809</th>\n",
       "      <td>0.049408</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029062</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152762 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_by_user_sequence  days_since_prior_order  \\\n",
       "207885  0.102878                      32                     8.0   \n",
       "2565    0.200077                       5                     6.0   \n",
       "74749   0.133904                       8                     9.0   \n",
       "52504   0.099180                      43                     1.0   \n",
       "167960  0.185663                      50                     7.0   \n",
       "...          ...                     ...                     ...   \n",
       "138319  0.067222                      64                     7.0   \n",
       "22463   0.128951                       1                    -1.0   \n",
       "110838  0.147027                      15                    30.0   \n",
       "89280   0.134167                      45                     6.0   \n",
       "26809   0.049408                      26                     5.0   \n",
       "\n",
       "        product_name  aisle_name  dept_name  prior_purchases  \\\n",
       "207885      0.251969    0.101280   0.138683                2   \n",
       "2565        0.126638    0.108402   0.124511                1   \n",
       "74749       0.096774    0.150568   0.138683                1   \n",
       "52504       0.093750    0.019435   0.034083                5   \n",
       "167960      0.028571    0.138187   0.132272                3   \n",
       "...              ...         ...        ...              ...   \n",
       "138319      0.000000    0.074534   0.091347                1   \n",
       "22463       0.046358    0.088060   0.138683                0   \n",
       "110838      0.128205    0.108402   0.124511                1   \n",
       "89280       0.222222    0.097122   0.088838               11   \n",
       "26809       0.000000    0.029062   0.034083                0   \n",
       "\n",
       "        purchased_percent_prior  free  fresh  ...  sweet  white  whole  rice  \\\n",
       "207885                 0.062500     0      0  ...      0      0      0     0   \n",
       "2565                   0.200000     0      0  ...      0      0      0     0   \n",
       "74749                  0.125000     0      0  ...      0      0      0     0   \n",
       "52504                  0.116279     0      0  ...      0      0      0     0   \n",
       "167960                 0.060000     0      0  ...      0      0      0     0   \n",
       "...                         ...   ...    ...  ...    ...    ...    ...   ...   \n",
       "138319                 0.015625     0      0  ...      0      0      0     0   \n",
       "22463                  0.000000     0      0  ...      0      0      0     0   \n",
       "110838                 0.066667     0      0  ...      0      0      0     0   \n",
       "89280                  0.244444     0      0  ...      0      0      0     0   \n",
       "26809                  0.000000     0      0  ...      0      0      0     0   \n",
       "\n",
       "        fruit  gluten   dow_sin   dow_cos      hour_sin      hour_cos  \n",
       "207885      0       0  0.974928 -0.222521 -5.000000e-01 -8.660254e-01  \n",
       "2565        0       0 -0.781831  0.623490 -8.660254e-01  5.000000e-01  \n",
       "74749       0       0  0.000000  1.000000 -8.660254e-01 -5.000000e-01  \n",
       "52504       0       0 -0.433884 -0.900969  1.224647e-16 -1.000000e+00  \n",
       "167960      0       0 -0.974928 -0.222521 -7.071068e-01 -7.071068e-01  \n",
       "...       ...     ...       ...       ...           ...           ...  \n",
       "138319      0       0  0.781831  0.623490  2.588190e-01  9.659258e-01  \n",
       "22463       0       0 -0.974928 -0.222521  9.659258e-01  2.588190e-01  \n",
       "110838      0       0 -0.781831  0.623490 -7.071068e-01  7.071068e-01  \n",
       "89280       0       0 -0.433884 -0.900969  5.000000e-01 -8.660254e-01  \n",
       "26809       0       0  0.781831  0.623490 -1.000000e+00 -1.836970e-16  \n",
       "\n",
       "[152762 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a Bayesian encoder. Start with LeaveOneOut. Even though it has less contaminiation\n",
    "# than other Bayesian encoders, it's a good idea to split data first. \n",
    "\n",
    "Xloo_train, Xloo_test, yloo_train, yloo_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "ce_loo = ce.leave_one_out.LeaveOneOutEncoder(cols=categorical_columns, random_state=43)\n",
    "ce_loo.fit(Xloo_train, yloo_train)\n",
    "Xloo_train = ce_loo.transform(Xloo_train)\n",
    "Xloo_test = ce_loo.transform(Xloo_test)\n",
    "\n",
    "Xloo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8c45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOut bagging conf matrix:  [[57784  1356]\n",
      " [ 4829  1501]]\n",
      "LeaveOneOut bagging f1 score:  0.3267660825078916\n",
      "LeaveOneOut bagging kappa score:  0.2836907700887702\n",
      "LeaveOneOut bagging roc_auc score:  0.6070980793159029\n"
     ]
    }
   ],
   "source": [
    "# Now try this encoded data in models after standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xloo_train_scaled = scaler.fit_transform(Xloo_train)\n",
    "Xloo_test_scaled = scaler.transform(Xloo_test)\n",
    "\n",
    "bgg_clf = BaggingClassifier()\n",
    "bgg_clf = bgg_clf.fit(Xloo_train_scaled, yloo_train)\n",
    "yloo_pred = bgg_clf.predict(Xloo_test_scaled)\n",
    "print('LeaveOneOut bagging conf matrix: ', metrics.confusion_matrix(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut bagging f1 score: ', metrics.f1_score(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut bagging kappa score: ', metrics.cohen_kappa_score(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut bagging roc_auc score: ', metrics.roc_auc_score(yloo_test, yloo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30aa2b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOut RF conf matrix:  [[58096  1044]\n",
      " [ 4729  1601]]\n",
      "LeaveOneOut RF f1 score:  0.35676880222841234\n",
      "LeaveOneOut RF kappa score:  0.317897202447431\n",
      "LeaveOneOut RF roc_auc score:  0.6176347820605081\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = rf_clf.fit(Xloo_train_scaled, yloo_train)\n",
    "yloo_pred = rf_clf.predict(Xloo_test_scaled)\n",
    "print('LeaveOneOut RF conf matrix: ', metrics.confusion_matrix(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut RF f1 score: ', metrics.f1_score(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut RF kappa score: ', metrics.cohen_kappa_score(yloo_test, yloo_pred))\n",
    "print('LeaveOneOut RF roc_auc score: ', metrics.roc_auc_score(yloo_test, yloo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f599b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_by_user_sequence</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_name</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>prior_purchases</th>\n",
       "      <th>purchased_percent_prior</th>\n",
       "      <th>free</th>\n",
       "      <th>fresh</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>white</th>\n",
       "      <th>whole</th>\n",
       "      <th>rice</th>\n",
       "      <th>fruit</th>\n",
       "      <th>gluten</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142503</th>\n",
       "      <td>0.174734</td>\n",
       "      <td>12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105725</td>\n",
       "      <td>0.081617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148008</th>\n",
       "      <td>0.092706</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.138340</td>\n",
       "      <td>0.122594</td>\n",
       "      <td>0.125702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42984</th>\n",
       "      <td>0.117207</td>\n",
       "      <td>23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.072368</td>\n",
       "      <td>0.089572</td>\n",
       "      <td>0.137006</td>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210745</th>\n",
       "      <td>0.094412</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>0.137006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173982</th>\n",
       "      <td>0.118372</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066869</td>\n",
       "      <td>0.050336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86479</th>\n",
       "      <td>0.199451</td>\n",
       "      <td>26</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.089572</td>\n",
       "      <td>0.137006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174893</th>\n",
       "      <td>0.118372</td>\n",
       "      <td>16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.064130</td>\n",
       "      <td>0.081617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115102</th>\n",
       "      <td>0.072350</td>\n",
       "      <td>40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.071550</td>\n",
       "      <td>0.081617</td>\n",
       "      <td>2</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172613</th>\n",
       "      <td>0.049054</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.032550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99709</th>\n",
       "      <td>0.085506</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.032550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152762 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_by_user_sequence  days_since_prior_order  \\\n",
       "142503  0.174734                      12                    15.0   \n",
       "148008  0.092706                      25                    10.0   \n",
       "42984   0.117207                      23                    10.0   \n",
       "210745  0.094412                       2                    21.0   \n",
       "173982  0.118372                       3                    17.0   \n",
       "...          ...                     ...                     ...   \n",
       "86479   0.199451                      26                     7.0   \n",
       "174893  0.118372                      16                    29.0   \n",
       "115102  0.072350                      40                    19.0   \n",
       "172613  0.049054                      12                     2.0   \n",
       "99709   0.085506                      15                     3.0   \n",
       "\n",
       "        product_name  aisle_name  dept_name  prior_purchases  \\\n",
       "142503      0.000000    0.105725   0.081617                1   \n",
       "148008      0.138340    0.122594   0.125702                3   \n",
       "42984       0.072368    0.089572   0.137006                2   \n",
       "210745      0.333333    0.138936   0.137006                1   \n",
       "173982      0.050000    0.066869   0.050336                1   \n",
       "...              ...         ...        ...              ...   \n",
       "86479       0.055556    0.089572   0.137006                1   \n",
       "174893      0.022727    0.064130   0.081617                1   \n",
       "115102      0.034483    0.071550   0.081617                2   \n",
       "172613      0.000000    0.009091   0.032550                1   \n",
       "99709       0.054054    0.024174   0.032550                1   \n",
       "\n",
       "        purchased_percent_prior  free  fresh  ...  sweet  white  whole  rice  \\\n",
       "142503                 0.083333     0      0  ...      0      0      0     1   \n",
       "148008                 0.120000     0      0  ...      0      0      0     0   \n",
       "42984                  0.086957     0      0  ...      0      0      0     0   \n",
       "210745                 0.500000     0      0  ...      0      0      0     0   \n",
       "173982                 0.333333     0      0  ...      0      0      1     0   \n",
       "...                         ...   ...    ...  ...    ...    ...    ...   ...   \n",
       "86479                  0.038462     0      0  ...      0      0      0     0   \n",
       "174893                 0.062500     0      0  ...      0      0      0     0   \n",
       "115102                 0.050000     0      0  ...      0      0      0     0   \n",
       "172613                 0.083333     0      0  ...      0      0      0     0   \n",
       "99709                  0.066667     0      0  ...      0      0      0     0   \n",
       "\n",
       "        fruit  gluten   dow_sin   dow_cos      hour_sin      hour_cos  \n",
       "142503      0       0  0.000000  1.000000  2.588190e-01 -9.659258e-01  \n",
       "148008      0       0  0.781831  0.623490  7.071068e-01 -7.071068e-01  \n",
       "42984       0       0  0.433884 -0.900969 -9.659258e-01 -2.588190e-01  \n",
       "210745      0       0 -0.974928 -0.222521  1.224647e-16 -1.000000e+00  \n",
       "173982      0       0  0.781831  0.623490 -9.659258e-01  2.588190e-01  \n",
       "...       ...     ...       ...       ...           ...           ...  \n",
       "86479       0       0 -0.974928 -0.222521 -5.000000e-01  8.660254e-01  \n",
       "174893      0       0 -0.433884 -0.900969  8.660254e-01 -5.000000e-01  \n",
       "115102      0       0  0.000000  1.000000 -7.071068e-01 -7.071068e-01  \n",
       "172613      0       0  0.781831  0.623490 -2.588190e-01 -9.659258e-01  \n",
       "99709       0       0  0.974928 -0.222521 -1.000000e+00 -1.836970e-16  \n",
       "\n",
       "[152762 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now see whether LeaveOneOut performs better if I set drop_invariant to True.\n",
    "\n",
    "Xloo_train, Xloo_test, yloo_train, yloo_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "ce_loo = ce.leave_one_out.LeaveOneOutEncoder(cols=categorical_columns, random_state=43,\n",
    "                                            drop_invariant=True)\n",
    "ce_loo.fit(Xloo_train, yloo_train)\n",
    "Xloo_train = ce_loo.transform(Xloo_train)\n",
    "Xloo_test = ce_loo.transform(Xloo_test)\n",
    "\n",
    "Xloo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "698a7cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO drop_invariant conf matrix:  [[58096  1039]\n",
      " [ 4754  1581]]\n",
      "LOO drop_invariant f1 score:  0.35309882747068677\n",
      "LOO drop_invariant kappa score:  0.3142729521833262\n",
      "LOO drop_invariant roc_auc score:  0.6159979683424727\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xloo_train_scaled = scaler.fit_transform(Xloo_train)\n",
    "Xloo_test_scaled = scaler.transform(Xloo_test)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = rf_clf.fit(Xloo_train_scaled, yloo_train)\n",
    "yloo_pred = rf_clf.predict(Xloo_test_scaled)\n",
    "print('LOO drop_invariant conf matrix: ', metrics.confusion_matrix(yloo_test, yloo_pred))\n",
    "print('LOO drop_invariant f1 score: ', metrics.f1_score(yloo_test, yloo_pred))\n",
    "print('LOO drop_invariant kappa score: ', metrics.cohen_kappa_score(yloo_test, yloo_pred))\n",
    "print('LOO drop_invariant roc_auc score: ', metrics.roc_auc_score(yloo_test, yloo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6c3a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/category_encoders/target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/category_encoders/target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_by_user_sequence</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_name</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>prior_purchases</th>\n",
       "      <th>purchased_percent_prior</th>\n",
       "      <th>free</th>\n",
       "      <th>fresh</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>white</th>\n",
       "      <th>whole</th>\n",
       "      <th>rice</th>\n",
       "      <th>fruit</th>\n",
       "      <th>gluten</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192482</th>\n",
       "      <td>0.026677</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.615385e-02</td>\n",
       "      <td>0.074484</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46172</th>\n",
       "      <td>0.068069</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.243697e-02</td>\n",
       "      <td>0.122973</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172513</th>\n",
       "      <td>0.053446</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.590839e-16</td>\n",
       "      <td>0.064567</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187970</th>\n",
       "      <td>0.079087</td>\n",
       "      <td>48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.162791e-01</td>\n",
       "      <td>0.041597</td>\n",
       "      <td>0.044824</td>\n",
       "      <td>7</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47198</th>\n",
       "      <td>0.068069</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.777778e-02</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194792</th>\n",
       "      <td>0.040936</td>\n",
       "      <td>5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.259259e-02</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80157</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.273504e-02</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>2</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212662</th>\n",
       "      <td>0.072175</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.117438e-02</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.969646e-05</td>\n",
       "      <td>0.110469</td>\n",
       "      <td>0.125823</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174838</th>\n",
       "      <td>0.126137</td>\n",
       "      <td>16</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.499449e-09</td>\n",
       "      <td>0.069872</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152762 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_by_user_sequence  days_since_prior_order  \\\n",
       "192482  0.026677                      10                     2.0   \n",
       "46172   0.068069                      16                     5.0   \n",
       "172513  0.053446                      10                     7.0   \n",
       "187970  0.079087                      48                     7.0   \n",
       "47198   0.068069                      23                     3.0   \n",
       "...          ...                     ...                     ...   \n",
       "194792  0.040936                       5                    30.0   \n",
       "80157   0.045455                      19                    14.0   \n",
       "212662  0.072175                      12                     6.0   \n",
       "8925    0.038462                       2                    30.0   \n",
       "174838  0.126137                      16                    29.0   \n",
       "\n",
       "        product_name  aisle_name  dept_name  prior_purchases  \\\n",
       "192482  9.615385e-02    0.074484   0.086256                1   \n",
       "46172   9.243697e-02    0.122973   0.125823                1   \n",
       "172513  4.590839e-16    0.064567   0.056469                1   \n",
       "187970  1.162791e-01    0.041597   0.044824                7   \n",
       "47198   7.777778e-02    0.110469   0.125823                1   \n",
       "...              ...         ...        ...              ...   \n",
       "194792  9.259259e-02    0.110469   0.125823                1   \n",
       "80157   4.273504e-02    0.061269   0.053123                2   \n",
       "212662  7.117438e-02    0.110469   0.125823                1   \n",
       "8925    8.969646e-05    0.110469   0.125823                0   \n",
       "174838  1.499449e-09    0.069872   0.034231                1   \n",
       "\n",
       "        purchased_percent_prior  free  fresh  ...  sweet  white  whole  rice  \\\n",
       "192482                 0.100000     0      0  ...      0      0      0     0   \n",
       "46172                  0.062500     0      0  ...      0      0      0     0   \n",
       "172513                 0.100000     0      0  ...      0      0      0     0   \n",
       "187970                 0.145833     0      0  ...      0      0      0     0   \n",
       "47198                  0.043478     0      0  ...      0      0      0     0   \n",
       "...                         ...   ...    ...  ...    ...    ...    ...   ...   \n",
       "194792                 0.200000     0      0  ...      0      0      0     0   \n",
       "80157                  0.105263     0      0  ...      0      0      0     0   \n",
       "212662                 0.083333     0      0  ...      0      0      0     0   \n",
       "8925                   0.000000     0      0  ...      0      0      0     0   \n",
       "174838                 0.062500     0      0  ...      0      0      0     0   \n",
       "\n",
       "        fruit  gluten   dow_sin   dow_cos      hour_sin  hour_cos  \n",
       "192482      0       0 -0.433884 -0.900969  5.000000e-01 -0.866025  \n",
       "46172       0       0 -0.781831  0.623490 -8.660254e-01  0.500000  \n",
       "172513      0       0  0.000000  1.000000 -8.660254e-01  0.500000  \n",
       "187970      0       0  0.781831  0.623490  8.660254e-01 -0.500000  \n",
       "47198       0       0  0.000000  1.000000 -7.071068e-01 -0.707107  \n",
       "...       ...     ...       ...       ...           ...       ...  \n",
       "194792      0       0 -0.433884 -0.900969 -7.071068e-01  0.707107  \n",
       "80157       0       0  0.781831  0.623490  1.224647e-16 -1.000000  \n",
       "212662      0       0 -0.781831  0.623490 -8.660254e-01 -0.500000  \n",
       "8925        0       0  0.781831  0.623490  7.071068e-01 -0.707107  \n",
       "174838      0       0 -0.433884 -0.900969  8.660254e-01 -0.500000  \n",
       "\n",
       "[152762 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model performance dropped very slighly when I dropped columns without variance. \n",
    "# Try some of the other Bayesian encoders. Start with Target Encoder.\n",
    "# It has hyperparameters min_sample_leaf and smoothing that I could tune if the Target encoder\n",
    "# seems worthwhile compared with others. \n",
    "\n",
    "Xtar_train, Xtar_test, ytar_train, ytar_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "ce_tar = ce.target_encoder.TargetEncoder(cols=categorical_columns)\n",
    "ce_tar.fit(Xtar_train, ytar_train)\n",
    "Xtar_train = ce_tar.transform(Xtar_train)\n",
    "Xtar_test = ce_tar.transform(Xtar_test)\n",
    "\n",
    "Xtar_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5c7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target RF conf matrix:  [[58258  1018]\n",
      " [ 4617  1577]]\n",
      "Target RF f1 score:  0.3588576629878257\n",
      "Target RF kappa score:  0.320919341297921\n",
      "Target RF roc_auc score:  0.6187136643100778\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xtar_train_scaled = scaler.fit_transform(Xtar_train)\n",
    "Xtar_test_scaled = scaler.transform(Xtar_test)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = rf_clf.fit(Xtar_train_scaled, ytar_train)\n",
    "ytar_pred = rf_clf.predict(Xtar_test_scaled)\n",
    "print('Target RF conf matrix: ', metrics.confusion_matrix(ytar_test, ytar_pred))\n",
    "print('Target RF f1 score: ', metrics.f1_score(ytar_test, ytar_pred))\n",
    "print('Target RF kappa score: ', metrics.cohen_kappa_score(ytar_test, ytar_pred))\n",
    "print('Target RF roc_auc score: ', metrics.roc_auc_score(ytar_test, ytar_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbdce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_by_user_sequence</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_name</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>prior_purchases</th>\n",
       "      <th>purchased_percent_prior</th>\n",
       "      <th>free</th>\n",
       "      <th>fresh</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>white</th>\n",
       "      <th>whole</th>\n",
       "      <th>rice</th>\n",
       "      <th>fruit</th>\n",
       "      <th>gluten</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79316</th>\n",
       "      <td>-0.722054</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.396136</td>\n",
       "      <td>-0.485932</td>\n",
       "      <td>-0.658074</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156437</th>\n",
       "      <td>-0.455851</td>\n",
       "      <td>16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.628249</td>\n",
       "      <td>-0.367699</td>\n",
       "      <td>-1.153288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214845</th>\n",
       "      <td>-0.340601</td>\n",
       "      <td>26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.469844</td>\n",
       "      <td>0.388614</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94258</th>\n",
       "      <td>-0.088164</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.349567</td>\n",
       "      <td>-1.644169</td>\n",
       "      <td>-0.942742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71645</th>\n",
       "      <td>-0.208395</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.810570</td>\n",
       "      <td>-0.485932</td>\n",
       "      <td>-0.658074</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149969</th>\n",
       "      <td>-0.143982</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.083536</td>\n",
       "      <td>0.469844</td>\n",
       "      <td>0.388614</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175072</th>\n",
       "      <td>0.276265</td>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.901542</td>\n",
       "      <td>-0.315713</td>\n",
       "      <td>-0.197089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-0.258819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63739</th>\n",
       "      <td>-0.394849</td>\n",
       "      <td>5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.656420</td>\n",
       "      <td>-1.155050</td>\n",
       "      <td>-1.153288</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191111</th>\n",
       "      <td>0.864465</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.801848</td>\n",
       "      <td>0.446848</td>\n",
       "      <td>0.347489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44115</th>\n",
       "      <td>0.997190</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.476094</td>\n",
       "      <td>-0.666176</td>\n",
       "      <td>0.347489</td>\n",
       "      <td>4</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152762 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  order_by_user_sequence  days_since_prior_order  \\\n",
       "79316  -0.722054                       5                     7.0   \n",
       "156437 -0.455851                      16                     6.0   \n",
       "214845 -0.340601                      26                     6.0   \n",
       "94258  -0.088164                      36                     5.0   \n",
       "71645  -0.208395                      23                     4.0   \n",
       "...          ...                     ...                     ...   \n",
       "149969 -0.143982                      17                     4.0   \n",
       "175072  0.276265                      18                    25.0   \n",
       "63739  -0.394849                       5                    20.0   \n",
       "191111  0.864465                       2                     7.0   \n",
       "44115   0.997190                      28                     6.0   \n",
       "\n",
       "        product_name  aisle_name  dept_name  prior_purchases  \\\n",
       "79316      -0.396136   -0.485932  -0.658074                1   \n",
       "156437     -0.628249   -0.367699  -1.153288                1   \n",
       "214845      0.476094    0.469844   0.388614                2   \n",
       "94258      -1.349567   -1.644169  -0.942742                1   \n",
       "71645      -0.810570   -0.485932  -0.658074                1   \n",
       "...              ...         ...        ...              ...   \n",
       "149969     -2.083536    0.469844   0.388614                1   \n",
       "175072     -0.901542   -0.315713  -0.197089                1   \n",
       "63739      -0.656420   -1.155050  -1.153288                1   \n",
       "191111      0.801848    0.446848   0.347489                1   \n",
       "44115       0.476094   -0.666176   0.347489                4   \n",
       "\n",
       "        purchased_percent_prior  free  fresh  ...  sweet  white  whole  rice  \\\n",
       "79316                  0.200000     0      0  ...      0      0      0     0   \n",
       "156437                 0.062500     0      0  ...      0      0      0     0   \n",
       "214845                 0.076923     0      0  ...      0      0      0     0   \n",
       "94258                  0.027778     0      0  ...      0      0      0     0   \n",
       "71645                  0.043478     0      0  ...      0      0      0     0   \n",
       "...                         ...   ...    ...  ...    ...    ...    ...   ...   \n",
       "149969                 0.058824     0      0  ...      0      0      0     0   \n",
       "175072                 0.055556     0      0  ...      0      0      0     0   \n",
       "63739                  0.200000     0      0  ...      0      0      0     0   \n",
       "191111                 0.500000     0      0  ...      0      0      0     0   \n",
       "44115                  0.142857     0      0  ...      0      0      0     0   \n",
       "\n",
       "        fruit  gluten   dow_sin   dow_cos      hour_sin  hour_cos  \n",
       "79316       0       0  0.781831  0.623490  1.224647e-16 -1.000000  \n",
       "156437      0       0 -0.433884 -0.900969  9.659258e-01 -0.258819  \n",
       "214845      0       0 -0.974928 -0.222521  5.000000e-01 -0.866025  \n",
       "94258       0       0  0.433884 -0.900969  1.224647e-16 -1.000000  \n",
       "71645       0       0 -0.974928 -0.222521 -2.588190e-01 -0.965926  \n",
       "...       ...     ...       ...       ...           ...       ...  \n",
       "149969      0       0 -0.974928 -0.222521  2.588190e-01 -0.965926  \n",
       "175072      0       0 -0.433884 -0.900969 -9.659258e-01 -0.258819  \n",
       "63739       0       0 -0.781831  0.623490  8.660254e-01 -0.500000  \n",
       "191111      0       0  0.433884 -0.900969 -7.071068e-01  0.707107  \n",
       "44115       0       0 -0.974928 -0.222521 -8.660254e-01 -0.500000  \n",
       "\n",
       "[152762 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TargetEncoder seems to perform slightly better than LeaveOneOut, even on these metrics\n",
    "# that are sensitive to over-fitting unbalanced data. Try WeightofEvidence.\n",
    "# It does have some parameters that could be tuned but don't bother for now. \n",
    "\n",
    "Xwoe_train, Xwoe_test, ywoe_train, ywoe_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "ce_woe = ce.woe.WOEEncoder(cols=categorical_columns)\n",
    "ce_woe.fit(Xwoe_train, ywoe_train)\n",
    "Xwoe_train = ce_woe.transform(Xwoe_train)\n",
    "Xwoe_test = ce_woe.transform(Xwoe_test)\n",
    "\n",
    "Xwoe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6776a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightofEvidence RF conf matrix:  [[57995  1018]\n",
      " [ 4829  1628]]\n",
      "WeightofEvidence RF f1 score:  0.3576842799077227\n",
      "WeightofEvidence RF kappa score:  0.3186168226815662\n",
      "WeightofEvidence RF roc_auc score:  0.6174395177732184\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xwoe_train_scaled = scaler.fit_transform(Xwoe_train)\n",
    "Xwoe_test_scaled = scaler.transform(Xwoe_test)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf = rf_clf.fit(Xwoe_train_scaled, ywoe_train)\n",
    "ywoe_pred = rf_clf.predict(Xwoe_test_scaled)\n",
    "print('WeightofEvidence RF conf matrix: ', metrics.confusion_matrix(ywoe_test, ywoe_pred))\n",
    "print('WeightofEvidence RF f1 score: ', metrics.f1_score(ywoe_test, ywoe_pred))\n",
    "print('WeightofEvidence RF kappa score: ', metrics.cohen_kappa_score(ywoe_test, ywoe_pred))\n",
    "print('WeightofEvidence RF roc_auc score: ', metrics.roc_auc_score(ywoe_test, ywoe_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea3297",
   "metadata": {},
   "source": [
    "WeightOfEvidence performed slightly less well than Target encoder and LeaveOneOut. \n",
    "\n",
    "Move forward with hyperparameter tuning. Already decided to keep LOO's drop_invariant as default False, and that seems to be the only parameter possibly worth changing. For Target, min_samples_leaf and smoothing values seem to take values greater than 0 (int and float, respectively). I've seen examples with these set to 2 instead of the default 1. Try a number of values to see what makes sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_leaf_options = [1,2,3,4,5,6,7,8,9,10]\n",
    "smoothing_options = [1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0]\n",
    "\n",
    "for leaf in min_sample_leaf_options:\n",
    "    for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2048c2",
   "metadata": {},
   "source": [
    "For resampling, under-sampling of non-reorders might actually be better than over-sampling reorders because I have such a big dataset; try out different methods and ratios of reordered:not. And/or, try SMOTE to generate synthetic samples; try penalized-SVM or other ways of penalizing models for poor precision/recall. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
