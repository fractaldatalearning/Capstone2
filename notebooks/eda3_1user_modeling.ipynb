{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a115ef9",
   "metadata": {},
   "source": [
    "Links to previous EDA work:\n",
    "\n",
    "- eda1, general exploration of the full, original datase, mostly consists of histograms comparing reorders:all orders feature-by-feature: https://github.com/fractaldatalearning/Capstone2/blob/main/notebooks/eda1_w_data_direct_from_wrangling.ipynb\n",
    "\n",
    "- eda2, creating new rows so that each order contains all newly-ordered items and reorders plus record of all items not re-ordered this time for the biggest user. Generally exploring some of this user's purchasing practices: https://github.com/fractaldatalearning/Capstone2/blob/main/notebooks/eda2_single_user.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105a0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from library.sb_utils import save_file\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b12278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34021 entries, 0 to 34020\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   order_id                34021 non-null  int64  \n",
      " 1   user_id                 34021 non-null  int64  \n",
      " 2   order_by_user_sequence  34021 non-null  int64  \n",
      " 3   order_dow               34021 non-null  int64  \n",
      " 4   order_hour_of_day       34021 non-null  int64  \n",
      " 5   days_since_prior_order  33995 non-null  float64\n",
      " 6   product_id              34021 non-null  int64  \n",
      " 7   add_to_cart_sequence    1992 non-null   float64\n",
      " 8   reordered               34021 non-null  float64\n",
      " 9   product_name            34021 non-null  object \n",
      " 10  aisle_name              34021 non-null  object \n",
      " 11  dept_name               34021 non-null  object \n",
      " 12  aisle_id                34021 non-null  float64\n",
      " 13  department_id           34021 non-null  float64\n",
      " 14  eval_set                1992 non-null   object \n",
      "dtypes: float64(5), int64(6), object(4)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get df with practice user's orders plus rows for non-reorders\n",
    "df = pd.read_csv('../data/processed/practice_user.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8306ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7': 'beverages',\n",
       " '16': 'dairy eggs',\n",
       " '19': 'snacks',\n",
       " '17': 'household',\n",
       " '4': 'produce',\n",
       " '14': 'breakfast',\n",
       " '13': 'pantry',\n",
       " '20': 'deli',\n",
       " '1': 'frozen',\n",
       " '11': 'personal care',\n",
       " '12': 'meat seafood',\n",
       " '6': 'international',\n",
       " '3': 'bakery',\n",
       " '15': 'canned goods',\n",
       " '9': 'dry goods pasta',\n",
       " '5': 'alcohol',\n",
       " '8': 'pets',\n",
       " '18': 'babies',\n",
       " '2': 'other',\n",
       " '21': 'missing',\n",
       " '10': 'bulk'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dictionaries connecting product-aisle-dept\n",
    "\n",
    "\n",
    "with open('../data/processed/dicts/aisle_dept_dict.txt', \n",
    "          'r') as ad_file:\n",
    "     ad_dict = json.load(ad_file)\n",
    "\n",
    "with open('../data/processed/dicts/prod_aisle_dict.txt', \n",
    "          'r') as pa_file:\n",
    "     pa_dict = json.load(pa_file)\n",
    "        \n",
    "with open('../data/processed/dicts/dept_id_name_dict.txt', \n",
    "          'r') as dd_file:\n",
    "     dd_dict = json.load(dd_file)\n",
    "        \n",
    "with open('../data/processed/dicts/aisle_id_name_dict.txt', \n",
    "          'r') as aa_file:\n",
    "     aa_dict = json.load(aa_file)\n",
    "        \n",
    "with open('../data/processed/dicts/prod_id_name_dict.txt', \n",
    "          'r') as pp_file:\n",
    "     pp_dict = json.load(pp_file)\n",
    "        \n",
    "dd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eb004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 'beverages',\n",
       " 16: 'dairy eggs',\n",
       " 19: 'snacks',\n",
       " 17: 'household',\n",
       " 4: 'produce',\n",
       " 14: 'breakfast',\n",
       " 13: 'pantry',\n",
       " 20: 'deli',\n",
       " 1: 'frozen',\n",
       " 11: 'personal care',\n",
       " 12: 'meat seafood',\n",
       " 6: 'international',\n",
       " 3: 'bakery',\n",
       " 15: 'canned goods',\n",
       " 9: 'dry goods pasta',\n",
       " 5: 'alcohol',\n",
       " 8: 'pets',\n",
       " 18: 'babies',\n",
       " 2: 'other',\n",
       " 21: 'missing',\n",
       " 10: 'bulk'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_dict = {int(k):v for k,v in pp_dict.items()}\n",
    "aa_dict = {int(k):v for k,v in aa_dict.items()}\n",
    "dd_dict = {int(k):v for k,v in dd_dict.items()}\n",
    "pa_dict = {int(k):v for k,v in pa_dict.items()}\n",
    "ad_dict = {int(k):v for k,v in ad_dict.items()}\n",
    "\n",
    "dd_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebe89c",
   "metadata": {},
   "source": [
    "In the initial notebooks I was just playing around and really exploring to see what data exists. Here, work to actually do what it would take to make predictions about this user's reorders, before moving into feature engineering on a bigger portion of the full dataset.\n",
    "\n",
    "Questions to answer:\n",
    "- Given an order of a product by a person (here, this person; later many users), what is the likelihood that they will reorder it ever? Reorder it again, and again? \n",
    "- Within a department/aisle, what portion of items get reordered, period? Reordered many times? (as opposed to what I calculated previously in notebook 1, which was the total ratio of reorders, with no regard for whether it was a particular user reordering something many times or something many people reorder occasionally, etc.) \n",
    "- How might I make new features that indicate specific reorder practices i.e. not just \"this is a reorder\" but \"this is a reorder, and it's this person's Nth time reordering the item\" or \"up until now, this person has reordered this item in p percent of all their orders.\"\n",
    "- In addition to the reorder column, what meaningful features can be engineered from other existing features (i.e: Column for 0/1 for whether product name contains \"organic.\")\n",
    "- What methods are best to use for engineering of features, getting dummies, etc?\n",
    "- Which models might be best for predicting this one user's reorders? What can I infer about whether similar methods will be useful on a dataset with more users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667070a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What portion of items does this person reorder, ever?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369dc6e4",
   "metadata": {},
   "source": [
    "Ready for preprocessing when this one user's orders are being predicted in a way I feel good about. Use what I learn with how to engineer features here to do so on a larger, random set of users from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f5ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
